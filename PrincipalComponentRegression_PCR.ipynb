{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cam2149/MachinelearningI/blob/main/PrincipalComponentRegression_PCR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Principal Component Regression (PCR)\n",
        "\n",
        "La regresión de componentes principales (PCR) es una técnica estadística para el análisis de regresión que se utiliza para reducir la dimensionalidad de un conjunto de datos proyectándolo en un subespacio de menor dimensión. Esto se hace encontrando un conjunto de combinaciones lineales ortogonales (es decir, no correlacionadas) de las variables originales, llamadas componentes principales, que capturan la mayor varianza en los datos. Los componentes principales se utilizan como predictores en el modelo de regresión, en lugar de las variables originales.\n",
        "\n",
        "La PCR se utiliza a menudo como alternativa a la regresión lineal múltiple, especialmente cuando el número de variables es grande o cuando las variables están correlacionadas. Al utilizar PCR, podemos reducir la cantidad de variables en el modelo y mejorar la interpretabilidad y estabilidad de los resultados de la regresión."
      ],
      "metadata": {
        "id": "3AipqDtAGawM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Características de la regresión de componentes principales (PCR)\n",
        "Estas son algunas de las características clave de la regresión de componentes principales (PCR):\n",
        "\n",
        "*   PCR reduce la dimensionalidad de un conjunto de datos proyectándolo en un subespacio de menor dimensión, utilizando un conjunto de combinaciones lineales ortogonales de las variables originales llamadas componentes principales.\n",
        "*   La PCR se utiliza a menudo como alternativa a la regresión lineal múltiple, especialmente cuando el número de variables es grande o cuando las variables están correlacionadas.\n",
        "*   Al utilizar PCR, podemos reducir la cantidad de variables en el modelo y mejorar la interpretabilidad y estabilidad de los resultados de la regresión.\n",
        "*   Para realizar la PCR, primero debemos estandarizar las variables originales y luego calcular los componentes principales utilizando la descomposición de valores singulares (SVD) o la descomposición propia de la matriz de covarianza de los datos estandarizados.\n",
        "*   Luego, los componentes principales se utilizan como predictores en un modelo de regresión lineal, cuyos coeficientes pueden estimarse mediante regresión de mínimos cuadrados o estimación de máxima verosimilitud."
      ],
      "metadata": {
        "id": "-9TeVZ2H60Wu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Desglosando las matemáticas detrás de la regresión de componentes principales (PCR)\n",
        "A continuación se ofrece una breve descripción general de los conceptos matemáticos subyacentes a la regresión de componentes principales (PCR):\n",
        "\n",
        "* **Reducción de dimensionalidad**: PCR reduce la dimensionalidad de un conjunto de datos proyectándolo en un subespacio de dimensiones inferiores, utilizando un conjunto de combinaciones lineales ortogonales de las variables originales llamadas componentes principales. Esta es una forma de resumir los datos capturando los patrones y relaciones más importantes en los datos mientras se ignora el ruido y la información irrelevante.\n",
        "* **Componentes principales**: los componentes principales de un conjunto de datos son las combinaciones lineales ortogonales de las variables originales que capturan la mayor varianza en los datos. Se obtienen realizando descomposición en valores singulares (SVD) o descomposición propia de la matriz de covarianza de los datos estandarizados. Por lo general, se elige que el número de componentes principales sea el número de variables, pero se puede reducir si hay una gran cantidad de colinealidad entre las variables.\n",
        "* **Regresión lineal**: PCR utiliza los componentes principales como predictores en un modelo de regresión lineal, cuyos coeficientes se pueden estimar mediante regresión de mínimos cuadrados o estimación de máxima verosimilitud. Luego, el modelo ajustado se puede utilizar para hacer predicciones sobre nuevos datos.\n",
        "\n",
        "#####En general, la PCR utiliza conceptos matemáticos del álgebra lineal y la estadística para reducir la dimensionalidad de un conjunto de datos y mejorar la interpretabilidad y estabilidad de los resultados de la regresión."
      ],
      "metadata": {
        "id": "Ovnnx2ic7pho"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Limitaciones de la regresión de componentes principales (PCR)\n",
        "\n",
        "Si bien la regresión de componentes principales (PCR) tiene muchas ventajas, también tiene algunas limitaciones que deben tenerse en cuenta al decidir si se utiliza para un análisis de regresión en particular:\n",
        "\n",
        "* La PCR sólo funciona bien con relaciones lineales: la PCR supone que la relación entre los predictores y la variable de respuesta es lineal. Si la relación no es lineal, es posible que la PCR no pueda capturarla con precisión, lo que genera predicciones sesgadas o inexactas. En tales casos, los métodos de regresión no lineal pueden ser más apropiados.\n",
        "* La PCR no maneja bien los valores atípicos: la PCR es sensible a los valores atípicos en los datos, lo que puede tener un impacto desproporcionado en los componentes principales y en el modelo de regresión ajustado. Por lo tanto, es importante identificar y manejar los valores atípicos en los datos antes de aplicar la PCR.\n",
        "* La PCR puede no ser interpretable: la PCR implica un procedimiento matemático complejo que genera un conjunto de combinaciones lineales ortogonales de las variables originales. Es posible que estas combinaciones lineales no sean fácilmente interpretables, especialmente si el número de variables es grande. Por el contrario, la regresión lineal múltiple es más interpretable, ya que utiliza las variables originales directamente como predictores.\n",
        "* Es posible que la PCR no sea eficiente: la PCR requiere una gran cantidad de cálculos, especialmente cuando el número de variables es grande. Por lo tanto, puede que no sea el método más eficaz para el análisis de regresión, especialmente cuando el conjunto de datos es grande. En tales casos, pueden ser más apropiados métodos de regresión más rápidos y eficientes.\n",
        "\n",
        "\n",
        "#####En general, si bien la PCR tiene muchas ventajas, es importante considerar cuidadosamente sus limitaciones y posibles inconvenientes antes de utilizarla para el análisis de regresión."
      ],
      "metadata": {
        "id": "VptGtn438bM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#¿Cómo se compara la regresión de componentes principales (PCR) con otras técnicas de análisis de regresión?\n",
        "\n",
        "La regresión de componentes principales (PCR) a menudo se compara con otras técnicas de análisis de regresión, como la regresión lineal múltiple, el análisis de componentes principales (PCA) y la regresión de mínimos cuadrados parciales (PLSR). A continuación se muestran algunas diferencias clave entre la PCR y estas otras técnicas:\n",
        "\n",
        "* **PCR frente a regresión lineal múltiple**: la PCR es similar a la regresión lineal múltiple, en el sentido de que ambas técnicas utilizan la regresión lineal para modelar la relación entre un conjunto de predictores y una variable de respuesta. Sin embargo, la PCR se diferencia de la regresión lineal múltiple en que reduce la dimensionalidad de los datos proyectándolos en un subespacio de dimensiones inferiores utilizando los componentes principales. Esto puede mejorar la interpretabilidad y estabilidad de los resultados de la regresión, especialmente cuando el número de variables es grande o cuando las variables están correlacionadas.\n",
        "* **PCR versus PCA: PCR es similar a PCA**, en el sentido de que ambas técnicas utilizan componentes principales para reducir la dimensionalidad de los datos. Sin embargo, la PCR se diferencia del PCA en que utiliza los componentes principales como predictores en un modelo de regresión lineal, mientras que el PCA es una técnica no supervisada que sólo analiza la estructura de los datos en sí, sin utilizar una variable de respuesta.\n",
        "* **PCR versus PLSR**: PCR es similar a PLSR, en el sentido de que ambas técnicas utilizan componentes principales para reducir la dimensionalidad de los datos y mejorar la interpretabilidad y estabilidad de los resultados de la regresión. Sin embargo, la PCR se diferencia del PLSR en que utiliza los componentes principales como predictores en un modelo de regresión lineal, mientras que el PLSR utiliza una combinación ponderada de las variables originales como predictores en un modelo de regresión de mínimos cuadrados parciales. Esto permite que PLSR capture mejor las relaciones no lineales entre los predictores y la variable de respuesta.\n",
        "\n",
        "#####En general, la PCR es una técnica útil para el análisis de regresión que se puede comparar con la regresión lineal múltiple, PCA y PLSR, según las características específicas de los datos y los objetivos del análisis.\n"
      ],
      "metadata": {
        "id": "1exhyfcZ9TqT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Regresión de componentes principales (PCR) en Python:"
      ],
      "metadata": {
        "id": "EDj5HcIt-KgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required modules\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Load the diabetes dataset\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "X, y = load_diabetes(return_X_y=True)\n",
        "X.shape\n"
      ],
      "metadata": {
        "id": "lfgWjt48OK37",
        "outputId": "5412e792-1af5-483a-cfd4-30e1895e5b77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(442, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora reduzcamos la dimensionalidad del conjunto de datos original a la mitad, es decir, de datos de 10 dimensiones a datos de 5 dimensiones. Cree una canalización con PCA y regresión lineal: se crea una canalización que consta de dos pasos: PCA y regresión lineal. El paso PCA se inicializa con el parámetro n_components establecido en 6, lo que significa que solo se conservarán los primeros seis componentes principales. El paso de regresión lineal se inicializa con los parámetros predeterminados.\n"
      ],
      "metadata": {
        "id": "Cn5Z_nXt-cRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a pipeline with PCA and linear regression\n",
        "pca = PCA(n_components=5)\n",
        "\n",
        "# Keep only the first six principal components\n",
        "reg = LinearRegression()\n",
        "pipeline = Pipeline(steps=[('pca', pca),\n",
        "\t\t\t\t\t\t('reg', reg)])\n",
        "\n",
        "# Fit the pipeline to the data\n",
        "pipeline.fit(X, y)\n",
        "\n",
        "# Predict the labels for the data\n",
        "y_pred = pipeline.predict(X)\n"
      ],
      "metadata": {
        "id": "LlGr0ksa-bwZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora evaluemos el rendimiento del modelo utilizando métricas como error absoluto medio, error cuadrático medio, error cuadrático medio y puntuación r2."
      ],
      "metadata": {
        "id": "Jxl6puLk-nbw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFWkUFTQ-0MO",
        "outputId": "41fc0315-70cf-4791-b94c-7cee25e46237"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features before PCR: 10\n",
            "Number of features after PCR: 5\n",
            "MAE: 44.30\n",
            "MSE: 2962.70\n",
            "RMSE: 54.43\n",
            "R^2: 0.50\n"
          ]
        }
      ],
      "source": [
        "# Compute the evaluation metrics\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = pipeline.score(X, y)\n",
        "\n",
        "# Print the number of features before and after PCR\n",
        "print(f'Number of features before PCR: {X.shape[1]}')\n",
        "print(f'Number of features after PCR: {pca.n_components_}')\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f'MAE: {mae:.2f}')\n",
        "print(f'MSE: {mse:.2f}')\n",
        "print(f'RMSE: {rmse:.2f}')\n",
        "print(f'R^2: {r2:.2f}')\n"
      ]
    }
  ]
}